{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchtext\n",
    "from torchtext.legacy.data import Field, BucketIterator\n",
    "\n",
    "import os\n",
    "\n",
    "from transformer import Transformer\n",
    "from utils import create_look_ahead_mask, create_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data fields\n",
    "SRC = Field(tokenize='spacy', tokenizer_language='en', init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "TRG = Field(tokenize='spacy', tokenizer_language='de', init_token='<sos>', eos_token='<eos>', lower=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load benchmarking dataset\n",
    "train_data, valid_data, test_data = torchtext.datasets.Multi30k.splits(exts=('.de', '.en'), fields=(TRG, SRC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build vocabularies\n",
    "SRC.build_vocab(train_data, min_freq=2)\n",
    "TRG.build_vocab(train_data, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define model parameters\n",
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "D_MODEL = 512\n",
    "N_HEADS = 8\n",
    "N_LAYERS = 6\n",
    "D_FF = 2048\n",
    "DROPOUT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "transformer = Transformer(\n",
    "    input_vocab_size=INPUT_DIM,\n",
    "    target_vocab_size=OUTPUT_DIM,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=N_HEADS,\n",
    "    num_encoder_layers=N_LAYERS,\n",
    "    num_decoder_layers=N_LAYERS,\n",
    "    dff=D_FF,\n",
    "    dropout_rate=DROPOUT\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=TRG.vocab.stoi['<pad>'])\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001)\n",
    "\n",
    "# Define batch size and max sequence length\n",
    "BATCH_SIZE = 128\n",
    "MAX_SEQ_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data iterators\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    datasets=(train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    repeat=False,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define number of training epochs\n",
    "N_EPOCHS = 10\n",
    "\n",
    "if not os.path.exists(\"checkpoints\"):\n",
    "    os.makedirs(\"checkpoints\")\n",
    "# Train model\n",
    "for epoch in range(N_EPOCHS):\n",
    "    transformer.train()\n",
    "    train_loss = 0\n",
    "    for i, batch in enumerate(train_iterator):\n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        src_mask = create_padding_mask(src)\n",
    "        trg_pad_mask = create_padding_mask(trg)\n",
    "        look_ahead_mask = create_look_ahead_mask(trg.shape[1])\n",
    "        trg_mask = torch.max(trg_pad_mask, look_ahead_mask.to(device))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = transformer(src, trg[:,:-1], src_mask, trg_mask, trg_pad_mask)\n",
    "        \n",
    "        # Reshape output and target to match loss function requirements\n",
    "        output = output.contiguous().view(-1, output.shape[-1])\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "        \n",
    "        loss = loss_fn(output, trg)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print progress every 100 batches\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch: {epoch+1}, Batch: {i+1}/{len(train_iterator)}, Train Loss: {train_loss/(i+1):.4f}')\n",
    "    \n",
    "    # Evaluate on validation set after each epoch\n",
    "    transformer.eval()\n",
    "    with torch.no_grad():\n",
    "        valid_loss = 0\n",
    "        for batch in valid_iterator:\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "            \n",
    "            src_mask = create_padding_mask(src)\n",
    "            trg_pad_mask = create_padding_mask(trg)\n",
    "            look_ahead_mask = create_look_ahead_mask(trg.shape[1])\n",
    "            trg_mask = torch.max(trg_pad_mask, look_ahead_mask.to(device))\n",
    "            \n",
    "            output, _ = transformer(src, trg[:,:-1], src_mask, trg_mask, trg_pad_mask)\n",
    "            \n",
    "            # Reshape output and target to match loss function requirements\n",
    "            output = output.contiguous().view(-1, output.shape[-1])\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            loss = loss_fn(output, trg)\n",
    "            valid_loss += loss.item()\n",
    "        \n",
    "        print(f'Epoch: {epoch+1}, Validation Loss: {valid_loss/len(valid_iterator):.4f}')\n",
    "    \n",
    "    # Define checkpoint path\n",
    "    checkpoint_path = f\"checkpoint_epoch_{epoch}.pt\"\n",
    "\n",
    "    # Save model state and optimizer state\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': transformer.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_loss': train_loss / (i+1),\n",
    "        'valid_loss': valid_loss / len(valid_iterator),\n",
    "    }, checkpoint_path)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and optimizer states\n",
    "torch.save({\n",
    "    'model_state_dict': transformer.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "}, 'transformer_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load saved model and optimizer states\n",
    "checkpoint = torch.load('transformer_model.pt')\n",
    "transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "# # Define checkpoint path\n",
    "# checkpoint_path = \"checkpoint_epoch_5.pt\"\n",
    "\n",
    "# # Load checkpoint\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "# transformer.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# train_loss = checkpoint['train_loss']\n",
    "# valid_loss = checkpoint['valid_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model\n",
    "# Define the input sequence\n",
    "input_sequence = 'This is a test.'\n",
    "\n",
    "# Preprocess the input sequence\n",
    "tokenized_sequence = SRC.tokenize(input_sequence)\n",
    "numericalized_sequence = [SRC.vocab.stoi[token] for token in tokenized_sequence]\n",
    "tensor_sequence = torch.LongTensor(numericalized_sequence).unsqueeze(1)\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_seq_len = 50\n",
    "\n",
    "# Pad the input sequence if necessary\n",
    "if tensor_sequence.shape[0] < max_seq_len:\n",
    "    padding = torch.LongTensor([[SRC.vocab.stoi['<pad>']] * (max_seq_len - tensor_sequence.shape[0])])\n",
    "    tensor_sequence = torch.cat([tensor_sequence, padding], dim=0)\n",
    "\n",
    "# Run the model on the input sequence\n",
    "output = transformer(tensor_sequence.to(device), None, None, None, None)[0]\n",
    "\n",
    "# Convert the output to tokens\n",
    "output_tokens = [TRG.vocab.itos[token_idx] for token_idx in output.argmax(dim=-1)]\n",
    "\n",
    "# Print the output\n",
    "print(' '.join(output_tokens))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
