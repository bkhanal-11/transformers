# Attention is All You Need

The implementation of transformer as presented in the paper !["Attention is all you need"](https://arxiv.org/abs/1706.03762) from scratch.
